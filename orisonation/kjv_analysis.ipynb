{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“– Analyzing KJV Vocab  \n",
    "\n",
    "I want my prayers to use vocabulary (stored in `myvocabulary.py`) that is Biblical in flavor.  But, while I have some idea of which words are biblical (e.g. \"myrrh\") and which are not (e.g. \"toothpaste\"), I am sure that the words contained within the KJV version are much more interesting than what ever  KJV-like words I could conjure with my dubiously-lettered mind. \n",
    "\n",
    "I don't have time to go through the Bible word by word.\n",
    "\n",
    "In this notebook I simply do some rudimentary analysis of words of various parts of speech, hastily surfacing those words that seem most \"Biblical.\"  I could have used a more statistically-robust technique for discovering key-words (e.g. Rayson & Garside's technique), but it seems sufficient for my purposes to simply compare the frequency of a word in the KJV with the frequency of that word in another corpus---for convenience, the Brown Corpus. \n",
    "\n",
    "I can then just copy and paste the Biblical words I \"discover\" into `myvocabulary.py`.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import corpus, FreqDist, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible = corpus.gutenberg.words('bible-kjv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_tagged = pos_tag(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown = corpus.brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist as fd \n",
    "biblefd = fd([w.lower() for w in bible])\n",
    "brownfd = fd([w.lower() for w in brown])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for comparing frequency of word in KJV vs. Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biblicity(word):\n",
    "    \"\"\"\n",
    "    Simple comparison of frequency between the word in the KJV vs. in Brown \n",
    "    \"\"\"\n",
    "    return biblefd[word]/max(brownfd[word],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN', 'NN', 'VBP', 'NN', 'NN', 'NN', 'VBD', 'NN', 'NN', 'NN']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "token2tags = defaultdict(list)\n",
    "for token,tag in bible_tagged:\n",
    "    token2tags[token].append(tag)\n",
    "    \n",
    "token2tags['shalt'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with the fact that pos-taggers don't work so well on archaic text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VBD'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_common(lst):#https://stackoverflow.com/a/1518632\n",
    "    return max(set(lst), key=lst.count)\n",
    "    \n",
    "def get_most_common_tag(word,nn_threshold=.7):\n",
    "    \"\"\"\n",
    "    get most common pos tag for a token\n",
    "    penalize NN since it is the default tag, often applied incorrectly\n",
    "    \"\"\"\n",
    "    most_common_tag = most_common(token2tags[word])\n",
    "    if most_common_tag==\"NN\":\n",
    "        if token2tags[word].count(\"NN\")/len(token2tags[word])>=nn_threshold:\n",
    "            return \"NN\"\n",
    "        else:\n",
    "            return most_common([t for t in token2tags[word] if t!=\"NN\"])\n",
    "    else:\n",
    "        return most_common_tag\n",
    "    return most_common_tag\n",
    "    \n",
    "    \n",
    "get_most_common_tag(\"shalt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for ranking words according to biblicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_words_based_on_pos(pos_start,strict=False):\n",
    "    \"\"\"\n",
    "    get top (most Biblical) n words in the KJV whose tag starts with pos_start (e.g. \"N\" or \"VBG\")\n",
    "    \"\"\"\n",
    "    if strict:\n",
    "        words = list(set([w for w in list(set(bible)) if get_most_common_tag(w)==pos_start]))\n",
    "    else:\n",
    "        words = list(set([w for w in list(set(bible)) if get_most_common_tag(w).startswith(pos_start)]))\n",
    "    words_biblicity = [(w,biblicity(w)) for w in words]\n",
    "    words_biblicity.sort(key=lambda x: x[1],reverse=True)\n",
    "    return words_biblicity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tops = sort_words_based_on_pos(\"NN\",strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ransom', 2.6),\n",
       " ('grief', 2.6),\n",
       " ('heir', 2.5714285714285716),\n",
       " ('word', 2.551094890510949),\n",
       " ('wood', 2.5454545454545454),\n",
       " ('day', 2.537117903930131),\n",
       " ('master', 2.513888888888889),\n",
       " ('dawning', 2.5),\n",
       " ('fortress', 2.5),\n",
       " ('raging', 2.5),\n",
       " ('draught', 2.5),\n",
       " ('brim', 2.5),\n",
       " ('cleansing', 2.5),\n",
       " ('sect', 2.5),\n",
       " ('gourd', 2.5),\n",
       " ('insurrection', 2.5),\n",
       " ('rump', 2.5),\n",
       " ('custody', 2.5),\n",
       " ('chastisement', 2.5),\n",
       " ('robber', 2.5),\n",
       " ('destruction', 2.473684210526316),\n",
       " ('devil', 2.44),\n",
       " ('solemn', 2.4166666666666665),\n",
       " ('cock', 2.4),\n",
       " ('correction', 2.4),\n",
       " ('noise', 2.3783783783783785),\n",
       " ('deed', 2.375),\n",
       " ('herb', 2.375),\n",
       " ('iron', 2.3488372093023258),\n",
       " ('thigh', 2.3333333333333335),\n",
       " ('thorn', 2.3333333333333335),\n",
       " ('banquet', 2.3333333333333335),\n",
       " ('greet', 2.2857142857142856),\n",
       " ('idol', 2.2857142857142856),\n",
       " ('man', 2.2659486329743164),\n",
       " ('flood', 2.263157894736842),\n",
       " ('twilight', 2.25),\n",
       " ('virginity', 2.25),\n",
       " ('warp', 2.25),\n",
       " ('vale', 2.25),\n",
       " ('mule', 2.25),\n",
       " ('honey', 2.24),\n",
       " ('voice', 2.234513274336283),\n",
       " ('faith', 2.225225225225225),\n",
       " ('city', 2.208651399491094),\n",
       " ('distress', 2.2),\n",
       " ('peace', 2.1666666666666665),\n",
       " ('prison', 2.142857142857143),\n",
       " ('pity', 2.142857142857143),\n",
       " ('journey', 2.142857142857143),\n",
       " ('oil', 2.126315789473684),\n",
       " ('widow', 2.1153846153846154),\n",
       " ('grave', 2.0606060606060606),\n",
       " ('shadow', 2.0277777777777777),\n",
       " ('bondmaid', 2.0),\n",
       " ('snail', 2.0),\n",
       " ('sparrow', 2.0),\n",
       " ('offscouring', 2.0),\n",
       " ('quaking', 2.0),\n",
       " ('sheepcote', 2.0),\n",
       " ('cistern', 2.0),\n",
       " ('newness', 2.0),\n",
       " ('gazingstock', 2.0),\n",
       " ('scroll', 2.0),\n",
       " ('enquiry', 2.0),\n",
       " ('waster', 2.0),\n",
       " ('viol', 2.0),\n",
       " ('zeal', 2.0),\n",
       " ('overlaying', 2.0),\n",
       " ('heron', 2.0),\n",
       " ('ospray', 2.0),\n",
       " ('inflammation', 2.0),\n",
       " ('manslayer', 2.0),\n",
       " ('dreameth', 2.0),\n",
       " ('bruit', 2.0),\n",
       " ('rie', 2.0),\n",
       " ('sabaoth', 2.0),\n",
       " ('dross', 2.0),\n",
       " ('remainest', 2.0),\n",
       " ('principality', 2.0),\n",
       " ('hemlock', 2.0),\n",
       " ('babbler', 2.0),\n",
       " ('archer', 2.0),\n",
       " ('husk', 2.0),\n",
       " ('prayest', 2.0),\n",
       " ('shrank', 2.0),\n",
       " ('gloominess', 2.0),\n",
       " ('acceptation', 2.0),\n",
       " ('watchtower', 2.0),\n",
       " ('causeway', 2.0),\n",
       " ('winebibber', 2.0),\n",
       " ('fellowprisoner', 2.0),\n",
       " ('thicket', 2.0),\n",
       " ('hornet', 2.0),\n",
       " ('drought', 2.0),\n",
       " ('brickkiln', 2.0),\n",
       " ('sheath', 2.0),\n",
       " ('horseman', 2.0),\n",
       " ('plat', 2.0),\n",
       " ('selvedge', 2.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[700:800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing words (and adding them) to those already in `myvocabulary.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myvocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'myvocabulary' from '/Users/kyle/Box Sync/computation/projects/TPwoC/orisonation/myvocabulary.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload  \n",
    "reload(myvocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "alreadywords = []\n",
    "\n",
    "for w in myvocabulary.myvocabulary[\"NN\"]:\n",
    "    if \">\" in w:\n",
    "        w1,w2 = w.split(\">\")\n",
    "        alreadywords.append(w1)\n",
    "        alreadywords.append(w2)\n",
    "    else:\n",
    "        alreadywords.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = sort_words_based_on_pos(\"NN\",strict=True)[900:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_already = [n for n,c in tops if n not in alreadywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensign',\n",
       " 'winefat',\n",
       " 'patriarchs',\n",
       " 'lowliness',\n",
       " 'bribe',\n",
       " 'desiredst',\n",
       " 'fryingpan',\n",
       " 'lama',\n",
       " 'dowry',\n",
       " 'curtain',\n",
       " 'partridge',\n",
       " 'flagon',\n",
       " 'stumblingstone',\n",
       " 'trump',\n",
       " 'sorcerer',\n",
       " 'camphire',\n",
       " 'lapwing',\n",
       " 'dimness',\n",
       " 'extortion',\n",
       " 'bier',\n",
       " 'solemnity',\n",
       " 'cuckow',\n",
       " 'shipmaster',\n",
       " 'fining',\n",
       " 'amiss',\n",
       " 'ninety',\n",
       " 'watercourse',\n",
       " 'bolster',\n",
       " 'fellowsoldier',\n",
       " 'slime']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_already[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just test to make sure that the words are in the word2vec vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Loading word2vec model: shrunkenvectors_200000.bin\n",
      "****Loaded\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "word2vec_path = \"shrunkenvectors_200000.bin\"\n",
    "print(\"****Loading word2vec model: %s\" % word2vec_path)\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "print(\"****Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive loop for going through words one by one, sorting some into a list, then (in cell below) joining them into a string that can be inserted into a list in `myvocabulary.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensign\n",
      "y\n",
      "patriarchs\n",
      "n\n",
      "bribe\n",
      "y\n",
      "lama\n",
      "\n",
      "dowry\n",
      "y\n",
      "curtain\n",
      "y\n",
      "partridge\n",
      "y\n",
      "trump\n",
      "\n",
      "sorcerer\n",
      "y\n",
      "extortion\n",
      "y\n",
      "solemnity\n",
      "y\n",
      "fining\n",
      "\n",
      "amiss\n",
      "\n",
      "ninety\n",
      "\n",
      "watercourse\n",
      "y\n",
      "bolster\n",
      "\n",
      "slime\n",
      "y\n",
      "pinnacle\n",
      "y\n",
      "furtherance\n",
      "\n",
      "glutton\n",
      "y\n",
      "heath\n",
      "y\n",
      "obstinate\n",
      "y\n",
      "wellspring\n",
      "y\n",
      "partiality\n",
      "y\n",
      "purification\n",
      "y\n",
      "regeneration\n",
      "y\n",
      "dial\n",
      "y\n",
      "spoon\n",
      "y\n",
      "kite\n",
      "y\n",
      "botch\n",
      "\n",
      "evangelist\n",
      "y\n",
      "fool\n",
      "y\n",
      "battle\n",
      "y\n",
      "wind\n",
      "y\n",
      "generation\n",
      "y\n",
      "flame\n",
      "y\n",
      "creature\n",
      "y\n",
      "month\n",
      "y\n",
      "household\n",
      "y\n",
      "valley\n",
      "y\n",
      "truth\n",
      "y\n",
      "prisoner\n",
      "y\n",
      "marvel\n",
      "y\n",
      "fountain\n",
      "y\n",
      "waste\n",
      "y\n",
      "thereto\n",
      "\n",
      "camp\n",
      "y\n",
      "mistress\n",
      "y\n",
      "province\n",
      "y\n",
      "wife\n",
      "y\n",
      "earthquake\n",
      "y\n",
      "accord\n",
      "y\n",
      "height\n",
      "y\n",
      "strength\n",
      "y\n",
      "hearth\n",
      "y\n",
      "hem\n",
      "y\n",
      "weaver\n",
      "y\n",
      "drunkenness\n",
      "y\n",
      "ornament\n",
      "y\n",
      "law\n",
      "y\n",
      "oven\n",
      "y\n",
      "condemnation\n",
      "y\n",
      "offspring\n",
      "y\n",
      "meek\n",
      "y\n",
      "ministry\n",
      "y\n",
      "rest\n",
      "y\n",
      "palm\n",
      "y\n",
      "goddess\n",
      "y\n",
      "sweetness\n",
      "y\n",
      "maker\n",
      "y\n",
      "drunkard\n",
      "y\n",
      "emerald\n",
      "y\n",
      "horseback\n",
      "y\n",
      "skull\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for w in not_already:\n",
    "    if w in word2vec.vocab:\n",
    "        print(w)\n",
    "        if input().startswith(\"y\"):\n",
    "            output.append(w)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"ensign\",\"bribe\",\"dowry\",\"curtain\",\"partridge\",\"sorcerer\",\"extortion\",\"solemnity\",\"watercourse\",\"slime\",\"pinnacle\",\"glutton\",\"heath\",\"obstinate\",\"wellspring\",\"partiality\",\"purification\",\"regeneration\",\"dial\",\"spoon\",\"kite\",\"evangelist\",\"fool\",\"battle\",\"wind\",\"generation\",\"flame\",\"creature\",\"month\",\"household\",\"valley\",\"truth\",\"prisoner\",\"marvel\",\"fountain\",\"waste\",\"camp\",\"mistress\",\"province\",\"wife\",\"earthquake\",\"accord\",\"height\",\"strength\",\"hearth\",\"hem\",\"weaver\",\"drunkenness\",\"ornament\",\"law\",\"oven\",\"condemnation\",\"offspring\",\"meek\",\"ministry\",\"rest\",\"palm\",\"goddess\",\"sweetness\",\"maker\",\"drunkard\",\"emerald\",\"horseback\",\"skull\"'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\"'+ '\",\"'.join(output)+ '\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes to myself*\n",
    "\n",
    "NN through 464 wwith small model\n",
    "\n",
    "harps,oxenwise,servile\n",
    "edification,reverence, dispossess,temperate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in vocab:\n",
    "    words = vocab[pos]\n",
    "    print(pos)\n",
    "    for w in words:\n",
    "        try:\n",
    "            w2v[w.split(\">\")[0]]\n",
    "        except:\n",
    "            print(\"%s not in word2vec vocab\" % w.split(\">\")[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
